# -*- coding: utf-8 -*-
"""CodeBERT-baseline-clean.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/10WEDgdKowI_cEPVXanPgpVgOhDDA7JYj

"""

from transformers import AutoTokenizer, AutoModel
import argparse
import torch
import torch.nn as nn
import torch.optim as optim
from torchtext.data import Field, BucketIterator
import math
import time
from torchtext import data
import torchtext.vocab as vocab
from lamner_utils.utils import set_seed, init_weights, print_log, get_max_lens, count_parameters, calculate_rouge, write_files, epoch_time
from src.attention import Attention
from src.encoder import Encoder
from src.decoder import Decoder
from six.moves import map
import bleu
import torch.nn as nn
import random
from six.moves import map
from tqdm import tqdm
import json
import os

tokenizer = AutoTokenizer.from_pretrained("huggingface/CodeBERTa-small-v1")
model = AutoModel.from_pretrained("huggingface/CodeBERTa-small-v1")

# with open("data_seq2seq/vocab.json", 'r') as f:
#   with open("data_seq2seq/vocab.txt", "w") as fc:
#     V = json.load(f)
#     l = len(V)
#     c = 1
#     for word in V:
#       tokens_ids = [V[word]]
#       embed = model(torch.tensor(tokens_ids)[None,:])[0][0][0].tolist()
#       fc.write(" ".join([word] + [str(j) for j in embed]))
#       if c < l :
#         fc.write("\n")
#       c += 1
                                 
# vocab_size = len(V)

CLS_INDEX = tokenizer.convert_tokens_to_ids(tokenizer.cls_token)
EOS_INDEX = tokenizer.convert_tokens_to_ids(tokenizer.eos_token)
PAD_INDEX = tokenizer.convert_tokens_to_ids(tokenizer.pad_token)
UNK_INDDEX = tokenizer.convert_tokens_to_ids(tokenizer.unk_token)

### seq2seq.py
class Seq2Seq(nn.Module):
  def __init__(self, encoder, decoder, src_pad_idx, device):
    super().__init__()
    
    self.encoder = encoder
    self.decoder = decoder
    self.src_pad_idx = src_pad_idx
    self.device = device
      
  def create_mask(self, src):
    mask = (src != self.src_pad_idx).permute(1, 0)
    return mask
      
  def forward(self, src, src_len, trg, teacher_forcing_ratio = 0.5):
      
    batch_size = src.shape[1]
    trg_len = trg.shape[0]
    trg_vocab_size = self.decoder.output_dim
    outputs = torch.zeros(trg_len, batch_size, trg_vocab_size).to(self.device)
    encoder_outputs, hidden = self.encoder(src, src_len)
    input = trg[0,:]
    mask = self.create_mask(src)

    for t in range(1, trg_len):
        
      output, hidden, _ = self.decoder(input, hidden, encoder_outputs, mask)
      outputs[t] = output
      teacher_force = random.random() < teacher_forcing_ratio
      top1 = output.argmax(1) 
      input = trg[t] if teacher_force else top1
        
    return outputs

def train(model, iterator, optimizer, criterion, clip):
  model.train()
  epoch_loss = 0
  for i, batch in enumerate(tqdm(iterator)): 
    src = batch.code
    src_len = torch.tensor([src.size(dim = 0)] * src.size(dim= 1))
    trg = batch.summary
    optimizer.zero_grad()
    output = model(src, src_len, trg)
    output_dim = output.shape[-1]
    output = output[1:].view(-1, output_dim)
    trg = trg[1:].view(-1)
    loss = criterion(output, trg)
    loss.backward()
    torch.nn.utils.clip_grad_norm_(model.parameters(), clip)
    optimizer.step()
    epoch_loss += loss.item()
      
  return epoch_loss / len(iterator)

def evaluate(model, iterator, criterion):
  model.eval()
  epoch_loss = 0
  with torch.no_grad():
    for i, batch in enumerate(iterator):
      src = batch.code
      src_len = torch.tensor([src.size(dim = 0)] * src.size(dim= 1))
      trg = batch.summary
      output = model(src, src_len, trg, 0)
      output_dim = output.shape[-1]      
      output = output[1:].view(-1, output_dim)
      trg = trg[1:].view(-1)
      loss = criterion(output, trg)
      epoch_loss += loss.item()
      
  return epoch_loss / len(iterator)

def translate_sentence(sentence, src_field, trg_field, model, device, max_len = 64):
  model.eval()
  tokens = [token.lower() for token in sentence]  
  tokens = [src_field.init_token] + tokens + [src_field.eos_token]      
  src_indexes = [src_field.vocab.stoi[token] for token in tokens]  
  src_tensor = torch.LongTensor(src_indexes).unsqueeze(1).to(device)
  src_len = torch.LongTensor([len(src_indexes)]).to(device)  
  with torch.no_grad():
    encoder_outputs, hidden = model.encoder(src_tensor, src_len)
  mask = model.create_mask(src_tensor)      
  trg_indexes = [trg_field.vocab.stoi[trg_field.init_token]]
  attentions = torch.zeros(max_len, 1, len(src_indexes)).to(device)  
  for i in range(max_len):
    trg_tensor = torch.LongTensor([trg_indexes[-1]]).to(device)            
    with torch.no_grad():
      output, hidden, attention = model.decoder(trg_tensor, hidden, encoder_outputs, mask)
    attentions[i] = attention
    if i>=2:
      output[0][trg_indexes[-2]] = 0
    output[0][trg_indexes[-1]] = 0       
    pred_token = output.argmax(1).item()    
    trg_indexes.append(pred_token)
    if pred_token == trg_field.vocab.stoi[trg_field.eos_token]:
      break  
  trg_tokens = [trg_field.vocab.itos[i] for i in trg_indexes]
  
  return trg_tokens[1:], attentions[:len(trg_tokens)-1]
  
def get_preds(data, src_field, trg_field, model, device, max_len = 64):    
  trgs = []
  pred_trgs = []  
  for datum in data:
    p = ""
    t= ""
    src = vars(datum)['code']
    trg = vars(datum)['summary']    
    pred_trg, _ = translate_sentence(src, src_field, trg_field, model, device, max_len)
    pred_trg = pred_trg[:-1]
    p = " ".join(pred_trg)
    p = p.strip()
    t = " ".join(trg)
    t = t.strip()
    pred_trgs.append(p)
    trgs.append(t)
      
  return pred_trgs,trgs


def translate_sentence_reps(sentence, src_field, trg_field, model, device, max_len = 64):

  model.eval()
  tokens = [token.lower() for token in sentence]
    

  tokens = [src_field.init_token] + tokens + [src_field.eos_token]
      
  src_indexes = [src_field.vocab.stoi[token] for token in tokens]
  
  src_tensor = torch.LongTensor(src_indexes).unsqueeze(1).to(device)

  src_len = torch.LongTensor([len(src_indexes)]).to(device)
  
  with torch.no_grad():
    encoder_outputs, hidden = model.encoder(src_tensor, src_len)

  mask = model.create_mask(src_tensor)
      
  trg_indexes = [trg_field.vocab.stoi[trg_field.init_token]]

  attentions = torch.zeros(max_len, 1, len(src_indexes)).to(device)
  
  for i in range(max_len):

    trg_tensor = torch.LongTensor([trg_indexes[-1]]).to(device)
            
    with torch.no_grad():
      output, hidden, attention = model.decoder(trg_tensor, hidden, encoder_outputs, mask)

    attentions[i] = attention
    if i>=2:
      output[0][trg_indexes[-2]] = 0
    output[0][trg_indexes[-1]] = 0
    pred_token = output.argmax(1).item()
    
    trg_indexes.append(pred_token)

    if pred_token == trg_field.vocab.stoi[trg_field.eos_token]:
      break
  
  trg_tokens = [trg_field.vocab.itos[i] for i in trg_indexes]
  
  return trg_tokens[1:], attentions[:len(trg_tokens)-1]

class Example(object):
    """A single training/test example."""
    def __init__(self,
                 idx,
                 source,
                 target,
                 ):
        self.idx = idx
        self.source = source
        self.target = target

def read_examples(filename):
    """Read examples from filename."""
    examples=[]
    with open(filename,encoding="utf-8") as f:
        for idx, line in enumerate(f):
            line=line.strip()
            js=json.loads(line)
            if 'idx' not in js:
                js['idx']=idx
            code=' '.join(js['code_tokens']).replace('\n',' ')
            code=' '.join(code.strip().split())
            nl=' '.join(js['docstring_tokens']).replace('\n','')
            nl=' '.join(nl.strip().split())            
            examples.append(
                Example(
                        idx = idx,
                        source=code,
                        target = nl,
                        ) 
            )
    return examples

def run_seq2seq(batch_size= 4, embedding_size= 512, hidden_dimension = 512, dropout = 0.5, epochs = 10, static = False, learning_rate = 0.01, infer = False):
  set_seed()
  CLIP = 1
  make_weights_static = static
  best_valid_loss = float('inf')
  cur_rouge = -float('inf')
  best_rouge = -float('inf')
  best_epoch = -1
  MIN_LR = 0.0000001
  MAX_VOCAB_SIZE = 50_000
  early_stop = False
  cur_lr = learning_rate
  num_of_epochs_not_improved = 0
  path = "data_seq2seq/"
  output_dir = "predictions/"


  #-------------------- OUR CODE---------------------#
  print("preparing data....")
  SRC = Field(
              init_token = tokenizer.cls_token, 
              eos_token = tokenizer.eos_token, 
              lower = False, 
              #include_lengths = True,
              fix_length = 256,
              pad_token=tokenizer.pad_token, 
              unk_token=tokenizer.unk_token)
  TRG = Field(
            init_token = tokenizer.cls_token, 
            eos_token = tokenizer.eos_token,
            lower = False,
            fix_length = 128,
            pad_token=tokenizer.pad_token, 
            unk_token=tokenizer.unk_token)
  
  train_data, valid_data, test_data = data.TabularDataset.splits(
          path=path, train='train_seq.csv',
          skip_header=True,
          validation='val_seq.csv', test='test_seq.csv', format='CSV',
          fields=[('code', SRC), ('summary', TRG)])


  # ------- TODOL how to generate codeBert_embeds ---------- #
  print("preparing vocab....")
  codeBERT = vocab.Vectors(name = path + 'vocab.txt')
  # ------- TODOL how to generate codeBert_embeds ---------- #

  SRC.build_vocab(train_data, 
                     max_size = MAX_VOCAB_SIZE, 
                     vectors = codeBERT
                   ) 

  TRG.build_vocab(train_data, 
                  max_size = MAX_VOCAB_SIZE 
                   )
  #-------------------- OUR CODE---------------------# 

  #*****************************************************************************************************
  print("preparing model....")
  device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
  train_iterator, valid_iterator, test_iterator = BucketIterator.splits(
          (train_data, valid_data, test_data), 
          batch_size = batch_size,
          sort_within_batch = True,
          shuffle=True,
          sort_key = lambda x : len(x.code),
          device = device)
  
  # for i,batch in enumerate(train_iterator):
  #   src = batch.code
  #   trg = batch.summary
  #   print(src)
  #   print(src.shape)
  #   print(trg)
  #   break


  
  INPUT_DIM = len(SRC.vocab)
  OUTPUT_DIM = len(TRG.vocab)
  attn = Attention(hidden_dimension, hidden_dimension)
  enc = Encoder(INPUT_DIM, embedding_size, hidden_dimension, hidden_dimension, dropout)
  dec = Decoder(OUTPUT_DIM, embedding_size, hidden_dimension, hidden_dimension, dropout, attn)
  model = Seq2Seq(enc, dec, PAD_INDEX, device).to(device)
  model.apply(init_weights)

  #*************************************************************************************
  print("Setting Embeddings")
  model.encoder.embedding.weight.data.copy_(SRC.vocab.vectors)

  #*************************************************************************************
  optimizer = optim.SGD(model.parameters(),lr=learning_rate, momentum=0.9)
  criterion = nn.CrossEntropyLoss(ignore_index = PAD_INDEX)
  cd_len = get_max_lens(train_data, test_data, valid_data, code=True)
  sm_len = get_max_lens(train_data, test_data, valid_data, code=False)
  print("Maximum Input length is " + str(cd_len) + "... Maximum Output Length is " + str(sm_len))
  print("Encoder Vocab Size " + str(INPUT_DIM) + "... Decoder Vocab Size " + str(OUTPUT_DIM))
  print("Batch Size:" + str(batch_size) + "\nEmbedding Dimension:" + str(embedding_size))
  print('The model has ' + str(count_parameters(model))+  ' trainable parameters')
  print("\nTraining Started.....")
  optimizer.param_groups[0]['lr'] = learning_rate
  
  if not(infer):
    for epoch in range(epochs):
      if MIN_LR>optimizer.param_groups[0]['lr']:
        early_stop = True
        break
  
      if num_of_epochs_not_improved==7:
        #reduce LR
        model.load_state_dict(torch.load(f'{output_dir}best-seq2seq.pt'))
        optimizer.param_groups[0]['lr'] = optimizer.param_groups[0]['lr'] * 0.1
        stepLR = optimizer.param_groups[0]['lr']
        num_of_epochs_not_improved = 0
      
      start_time = time.time()
      
      train_loss = train(model, train_iterator, optimizer, criterion, CLIP)
      valid_loss = evaluate(model, valid_iterator, criterion)
      p, t = get_preds(valid_data, SRC, TRG, model, device)
      write_files(p,t,epoch+1)
      cur_rouge = calculate_rouge(epoch+1)
      torch.save(model.state_dict(), f'{output_dir}seq2seq-'+str(epoch+1)+'.pt')
  
      if best_valid_loss>valid_loss:
        best_valid_loss = valid_loss
        best_epoch = epoch + 1
        num_of_epochs_not_improved = 0
      else:
        num_of_epochs_not_improved = num_of_epochs_not_improved + 1 
      
      if cur_rouge > best_rouge:
        best_rouge = cur_rouge
        torch.save(model.state_dict(), f'{output_dir}best-seq2seq.pt')
      
      if make_weights_static==True:
        model.encoder.embedding.weight.requires_grad=False
        make_weights_static=False
        print("Embeddings are static now")
      end_time = time.time()
      epoch_mins, epoch_secs = epoch_time(start_time, end_time)
  
      print('Epoch: ' + str(epoch+1) + ' | Time: '+ str(epoch_mins) + 'm' +  str(epoch_secs) + 's')
      print('\t Learning Rate: ' + str(optimizer.param_groups[0]['lr']))
      print('\t Train Loss: ' + str(round(train_loss, 2)) + ' | Train PPL: ' + str(round(math.exp(train_loss), 2)))
      print('\t Val. Loss: ' + str(round(valid_loss, 2 )) + ' |  Val. PPL: '+ str(round(math.exp(valid_loss), 2)))
      print('\t Current Val. Rouge: ' + str(cur_rouge) + ' |  Best Rouge '+ str(best_rouge) + ' |  Best Epoch '+ str(best_epoch))
      print('\t Number of Epochs of no Improvement '+ str(num_of_epochs_not_improved))

  model.load_state_dict(torch.load(f'{output_dir}best-seq2seq.pt'))
  test_loss = evaluate(model, test_iterator, criterion)
  print('Test Loss: ' + str(round(test_loss, 2)) + ' | Test PPL: ' + str(round(math.exp(test_loss), 2)))
  p, t = get_preds(test_data, SRC, TRG, model, device)
  # write_files(p,t,epoch=0, test=True)
  
  eval_examples = read_examples(f'{path}test.jsonl')
  predictions = []
  with open(os.path.join(output_dir,"test.output"),'w') as f, open(os.path.join(output_dir,"test.gold"),'w') as f1:
      for ref,gold in zip(p,eval_examples):
          predictions.append(str(gold.idx)+'\t'+ref)
          f.write(str(gold.idx)+'\t'+ref+'\n')
          f1.write(str(gold.idx)+'\t'+gold.target+'\n')     

  (goldMap, predictionMap) = bleu.computeMaps(predictions, os.path.join(output_dir, "test.gold")) 
  dev_bleu=round(bleu.bleuFromMaps(goldMap, predictionMap)[0],2)
  print("  %s = %s "%("bleu-4",str(dev_bleu)))
  print("  "+"*"*20) 
  
#if __name__ == '__main__':
#  main()

run_seq2seq(batch_size = 16, embedding_size=768, epochs = 10)

"""# Evaluation"""

run_seq2seq(batch_size = 16, embedding_size=768, epochs = 5, infer = True)
